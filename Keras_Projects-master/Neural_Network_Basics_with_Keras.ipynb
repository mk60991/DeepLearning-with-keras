{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Basics with Keras\n",
    "\n",
    " Classify movie reviews as positive or negative (binary classification)\n",
    "\n",
    " Classify news wires by topic (multiclass classification)\n",
    "\n",
    " Estimate the price of a house, given real-estate data (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of a Neural Network\n",
    " - ***Layers***, which are combined into a ***network*** (or ***model***)\n",
    " - The ***input data*** and corresponding ***targets***\n",
    " - The ***loss function***, which defines the feedback signal used for learning\n",
    " - The ***optimizer***, which determines how learning proceeds\n",
    "\n",
    "![capture](https://user-images.githubusercontent.com/13174586/49500209-25565d80-f896-11e8-953f-c1b9a7fba39c.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "The fundamental data structure in neural networks is the ***layer***. A layer is a data-processing module that takes as input one or more tensors and that outputs one or more tensors. Some layers are stateless, but more frequently layers have a state: the layer’s *weights*, one or several tensors learned with *stochastic gradient descent*, which together contain the network’s *knowledge*.\n",
    "\n",
    "Different layers are appropriate for different tensor formats and different types of data processing. For instance, simple vector data, stored in 2D tensors of shape *(samples, features)*, is often processed by ***densely connected layers***, also called ***fully connected*** or ***dense layers (the Dense class in Keras)***. Sequence data, stored in 3D tensors of shape *(samples, timesteps, features)*, is typically processed by ***recurrent layers*** such as an ***LSTM layer***. Image data, stored in 4D tensors, is usually processed by ***2D convolution layers (Conv2D)***.\n",
    "\n",
    "Neural Networks have ***layer compatibility*** rule. Every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "layer= layers.Dense(32, input_shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re creating a layer that will only accept as input 2D tensors where the first dimension is 784 (axis 0, the batch dimension, is unspecified, and thus any value would be accepted). This layer will return a tensor where the first dimension has been transformed to be 32.\n",
    "\n",
    "Using ***Keras***, we don’t have to worry about compatibility, because the layers we add to our models are dynamically built to match the shape of the incoming layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer didn’t receive an input shape argument—instead, it automatically\n",
    "inferred its input shape as being the output shape of the layer that came before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models: Network of layers\n",
    "\n",
    "A deep-learning model is a directed, acyclic graph of layers. The most common\n",
    "instance is a linear stack of layers, mapping a single input to a single output.\n",
    "\n",
    "Few other networks are:\n",
    " - Two-branch networks\n",
    " - Multihead networks\n",
    " - Inception blocks\n",
    " \n",
    "The topology of a network defines a *hypothesis space*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions & Optimizers\n",
    "\n",
    "Once the network architecture is defined, we have to choose two more things:\n",
    " - **Loss function (objective function)—** The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
    " - **Optimizer—** Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\n",
    " \n",
    "A neural network that has multiple outputs may have multiple loss functions (one per output). But the gradient-descent process must be based on a single scalar loss value; so, for multi-loss networks, all losses are combined (via averaging) into a single scalar quantity.\n",
    "\n",
    "```binary crossentropy``` for a ***two-class classification problem***\n",
    "\n",
    "```categorical crossentropy``` for a ***many-class classification problem*** \n",
    "\n",
    "```meansquared error``` for a ***regression problem***\n",
    "\n",
    "```connectionist temporal classification (CTC)``` for a ***sequence-learning problem***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing Network with Keras\n",
    "\n",
    "Typical Workflow:\n",
    " - Define training Data: input and target tensors\n",
    " - Define network of layers taht maps inputs to targets\n",
    " - Configure learning process by choosing loss funtion, optimizer and metrics to monitor\n",
    " - iterate on training data by calling ```fit``` on the model\n",
    " \n",
    "There are two ways to denine model:\n",
    " - Using ```Sequential()```\n",
    " - Using **Functional API**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Model\n",
    "\n",
    "from keras import models, layers\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\soumyama\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Functional API\n",
    "\n",
    "input_tensor= layers.Input(shape=(784,))\n",
    "x= layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor= layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model= models.Model(input=input_tensor, output=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functional API, we’re manipulating the data tensors that the model processes and applying layers to this tensor \n",
    "as if they were functions.\n",
    "\n",
    "\n",
    "The learning process is configured in the *compilation* step, where we specify the **optimizer** and **loss function(s)** that the model should use, as well as the metrics we want to monitor during training. Below is an example with a single loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning process consists of passing *Numpy* arrays of input data (and the corresponding target data) to the model via the ```fit()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, target_data, epochs=10, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
