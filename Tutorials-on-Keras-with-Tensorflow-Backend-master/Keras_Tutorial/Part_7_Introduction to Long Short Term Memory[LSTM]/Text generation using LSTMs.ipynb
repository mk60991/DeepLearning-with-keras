{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies numpy and keras\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading text file and creating character to integer mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "filename = \"./sentence_data.txt\"\n",
    "\n",
    "text = (open(filename).read()).lower()\n",
    "\n",
    "# mapping characters with integers\n",
    "unique_chars = sorted(list(set(text)))\n",
    "\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "for i, c in enumerate (unique_chars):\n",
    "    char_to_int.update({c: i})\n",
    "    int_to_char.update({i: c})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text file is open, and all characters are converted to lowercase letters. In order to facilitate the following steps, we would be mapping each character to a respective number. This is done to make the computation part of the LSTM easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input and output dataset\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(0, len(text) - 50, 1):\n",
    "    sequence = text[i:i + 50]\n",
    "    label =text[i + 50]\n",
    "    X.append([char_to_int[char] for char in sequence])\n",
    "    Y.append(char_to_int[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 25, 22, 1, 36, 34, 18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29]\n",
      "[25, 22, 1, 36, 34, 18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18]\n",
      "[22, 1, 36, 34, 18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9]\n",
      "[1, 36, 34, 18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0]\n",
      "[36, 34, 18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0, 0]\n",
      "[34, 18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0, 0, 36]\n",
      "[18, 24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0, 0, 36, 25]\n",
      "[24, 22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0, 0, 36, 25, 37]\n",
      "[22, 21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0, 0, 36, 25, 37, 30]\n",
      "[21, 26, 22, 1, 31, 23, 1, 29, 18, 20, 19, 22, 36, 25, 0, 0, 18, 20, 36, 37, 35, 1, 32, 34, 26, 29, 37, 35, 9, 1, 35, 20, 31, 22, 30, 18, 1, 32, 34, 26, 29, 18, 9, 0, 0, 36, 25, 37, 30, 21]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is prepared in a format such that if we want the LSTM to predict the ‘O’ in ‘HELLO’  we would feed in [‘H’, ‘E‘ , ‘L ‘ , ‘L‘ ] as the input and [‘O’] as the expected output. Similarly, here we fix the length of the sequence that we want (set to 50 in the example) and then save the encodings of the first 49 characters in X and the expected output i.e. the 50th character in Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Reshaping of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping, normalizing and one hot encoding\n",
    "X_modified = numpy.reshape(X, (len(X), 50, 1))\n",
    "X_modified = X_modified / float(len(unique_chars))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LSTM network expects the input to be in the form [samples, time steps, features] where samples is the number of data points we have, time steps is the number of time-dependent steps that are there in a single data point, features refers to the number of variables we have for the corresponding true value in Y. We then scale the values in X_modified between 0 to 1 and one hot encode our true values in Y_modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Defining the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(300, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sequential model which is a linear stack of layers is used. The first layer is an LSTM layer with 300 memory units and it returns sequences. This is done to ensure that the next LSTM layer receives sequences and not just randomly scattered data. A dropout layer is applied after each LSTM layer to avoid overfitting of the model. Finally, we have the last layer as a fully connected layer with a ‘softmax’ activation and neurons equal to the number of unique characters, because we need to output one hot encoded result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fitting and generating characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100270/100270 [==============================] - 1846s 18ms/step - loss: 2.7437\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "model.fit(X_modified, Y_modified, epochs=1, batch_size=30)\n",
    "\n",
    "# picking a random seed\n",
    "start_index = numpy.random.randint(0, len(X)-1)\n",
    "new_string = X[start_index]\n",
    "\n",
    "# generating characters\n",
    "for i in range(50):\n",
    "    x = numpy.reshape(new_string, (1, len(new_string), 1))\n",
    "    x = x / float(len(unique_chars))\n",
    "\n",
    "    #predicting\n",
    "    pred_index = numpy.argmax(model.predict(x, verbose=0))\n",
    "    char_out = int_to_char[pred_index]\n",
    "    seq_in = [int_to_char[value] for value in new_string]\n",
    "    print(char_out)\n",
    "\n",
    "    new_string.append(pred_index)\n",
    "    new_string = new_string[1:len(new_string)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
